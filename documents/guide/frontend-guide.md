# EchoAI — Frontend Integration Guide
>
> **What does it cover?** Every API endpoint you need, exactly what to send, exactly what comes back, and how to display it.

---

## Table of Contents

1. [Quick Orientation](#1-quick-orientation)
2. [Authentication](#2-authentication)
3. [App Manager Chat — SSE Streaming](#3-app-manager-chat--sse-streaming)
4. [Workflow Chat — WebSocket Streaming](#4-workflow-chat--websocket-streaming)
5. [A2UI — How to Render the Progress UI](#5-a2ui--how-to-render-the-progress-ui)
6. [Error Handling Reference](#6-error-handling-reference)
7. [Copy-Paste Code Snippets](#7-copy-paste-code-snippets)

---

## 1. Quick Orientation

The system has **two separate products** with different streaming approaches:

| Product | What it does | Streaming method |
|---|---|---|
| **App Manager** | Published apps that end users chat with | **POST + SSE** (Server-Sent Events) |
| **Workflow Builder** | Designer/developer tests a workflow under construction | **POST then WebSocket** |

The App Manager stream also sends **A2UI messages** — a structured format that tells the frontend what "progress steps" to render (think a live step-tracker UI). The Workflow WebSocket sends raw JSON events for the same purpose.

---

## 2. Authentication

All endpoints require a Bearer token in the `Authorization` header.

```
Authorization: Bearer <access_token>
```

Obtain the token from the existing login endpoint (unchanged, not documented here). Pass it on every request.

---

## 3. App Manager Chat — SSE Streaming

### Overview (in plain English)

1. User types a message in your chat UI.
2. You `POST` to the stream endpoint with the message.
3. The server immediately starts sending back a stream of events (like a live feed).
4. You read each event, parse it, and update the UI.
5. The stream closes when the answer is complete.

### Step 1 — Send the message and open the stream

```
POST /api/applications/{application_id}/chat/stream
```

**Path parameter**

| Param | Type | Example |
|---|---|---|
| `application_id` | UUID string | `"3fa85f64-5717-4562-b3fc-2c963f66afa6"` |

**Request headers**

```
Content-Type: application/json
Authorization: Bearer <token>
```

**Request body**

```json
{
  "message": "What are the latest security incidents?",
  "session_id": "abc-123-optional"
}
```

| Field | Required | Notes |
|---|---|---|
| `message` | Yes | The user's text |
| `session_id` | No | Pass the same value across messages to keep conversation history. Leave out for a fresh session. |

**Error responses before the stream opens**

| Status | Meaning |
|---|---|
| `400` | Application is not published yet — cannot chat |
| `401` | Token missing or expired |
| `404` | Application not found |

---

### Step 2 — Read the stream

The response has `Content-Type: text/event-stream`. Each event looks like:

```
data: {"type":"surfaceUpdate", ...}\n\n
data: {"type":"dataModelUpdate", ...}\n\n
```

> **Important:** `EventSource` (browser built-in) only supports GET requests. Since this is a POST, you must use `fetch` + `ReadableStream`. See [Section 7](#7-copy-paste-code-snippets) for the exact code.

---

### Step 3 — Handle the events (A2UI messages)

The stream sends **4 types of messages** in this order:

#### Message 1: `surfaceUpdate` — defines the UI layout (sent once)

```json
{
  "type": "surfaceUpdate",
  "surfaceId": "exec_abc123def456",
  "catalog": "std:v1",
  "components": [ ... ]
}
```

- `surfaceId` is auto-generated by the backend. **Save it** — you'll need it to match all subsequent messages.
- `components` describes the layout. You don't need to parse this deeply — see [Section 5](#5-a2ui--how-to-render-the-progress-ui) for a simpler approach.

#### Message 2: `dataModelUpdate` — initial empty data (sent once, right after surfaceUpdate)

```json
{
  "type": "dataModelUpdate",
  "surfaceId": "exec_abc123def456",
  "data": {
    "title": "Processing your request...",
    "steps": [],
    "final_output": ""
  }
}
```

This is the starting state. Steps list is empty, final output is blank.

#### Message 3: `beginRendering` — signal to show the UI (sent once)

```json
{
  "type": "beginRendering",
  "surfaceId": "exec_abc123def456",
  "rootComponentId": "root"
}
```

When you receive this, show the progress UI to the user.

#### Message 4: `dataModelUpdate` (steps) — live progress updates (sent many times)

```json
{
  "type": "dataModelUpdate",
  "surfaceId": "exec_abc123def456",
  "data": {
    "steps": [
      {
        "id": "guardrails",
        "icon": "shield",
        "label": "Guardrails",
        "detail": "",
        "status": "completed"
      },
      {
        "id": "enhancer",
        "icon": "auto_fix_high",
        "label": "Prompt Enhancement",
        "detail": "",
        "status": "running"
      },
      {
        "id": "orchestrator",
        "icon": "account_tree",
        "label": "Planning",
        "detail": "",
        "status": "pending"
      }
    ]
  }
}
```

> **Replace the entire `steps` array every time you get this** — the backend always sends the full list.

**Step `status` values:**

| Value | What to show |
|---|---|
| `pending` | Grey / not started |
| `running` | Spinner / animated |
| `completed` | Green checkmark |
| `failed` | Red X |
| `interrupted` | Orange pause |
| `skipped` | Grey, dimmed |

**All possible steps and their icons** (Material Icons names):

| `id` | `icon` | `label` |
|---|---|---|
| `guardrails` | `shield` | Guardrails |
| `enhancer` | `auto_fix_high` | Prompt Enhancement |
| `rag` | `search` | Document Retrieval |
| `orchestrator` | `account_tree` | Planning |
| `dispatch` | `play_circle` | Skill Dispatch |
| `agent_<name>` | `smart_toy` | Agent: Name |

#### Message 5: `dataModelUpdate` (final output) — the answer (last message before stream closes)

```json
{
  "type": "dataModelUpdate",
  "surfaceId": "exec_abc123def456",
  "data": {
    "final_output": "Here is a summary of the latest security incidents:\n\n1. ..."
  }
}
```

When you see `final_output` in the data (non-empty), display it as the assistant's reply in the chat.

#### Message 6: `deleteSurface` — cleanup (optional, may be sent on error)

```json
{
  "type": "deleteSurface",
  "surfaceId": "exec_abc123def456"
}
```

Hide / remove the progress UI when this arrives.

---

### Complete flow diagram

```
User sends message
       │
       ▼
POST /api/applications/{id}/chat/stream
       │
       ▼
 ┌─────────────────────────────────────────────────┐
 │  Stream events arrive one by one:               │
 │                                                 │
 │  surfaceUpdate    → save surfaceId              │
 │  dataModelUpdate  → initial empty state         │
 │  beginRendering   → SHOW progress UI            │
 │  dataModelUpdate  → steps[guardrails: running]  │
 │  dataModelUpdate  → steps[guardrails: done,     │
 │                           enhancer: running]    │
 │  dataModelUpdate  → steps[..., planning: done,  │
 │                           dispatch: running]    │
 │  dataModelUpdate  → final_output = "Answer..."  │
 │  (stream closes)  → SHOW answer in chat         │
 └─────────────────────────────────────────────────┘
```

---

## 4. Workflow Chat — WebSocket Streaming

### Overview (in plain English)

The Workflow product uses a **two-step pattern**:

1. You call a REST endpoint to start a chat session (one time per workflow).
2. For each user message, you call a REST endpoint that returns a `run_id` immediately.
3. **Before the execution starts**, you open a WebSocket using that `run_id`.
4. The WebSocket sends you live events as the workflow runs.

> The 500ms delay built into the backend gives you time to connect the WebSocket before execution begins.

---

### Step 1 — Start a chat session (once per workflow)

```
POST /workflows/chat/start
```

**Request body**

```json
{
  "workflow_id": "wf_550e8400e29b41d4a716446655440000",
  "mode": "test",
  "version": null,
  "initial_context": {}
}
```

| Field | Required | Notes |
|---|---|---|
| `workflow_id` | Yes | Format: `wf_` prefix + 32 hex chars |
| `mode` | No | `"test"` (default) or `"production"` |
| `version` | No | `null` for latest |
| `initial_context` | No | Key-value pairs passed to workflow agents |

**Response**

```json
{
  "session_id": "session_abc123...",
  "workflow_id": "wf_550e...",
  "mode": "test",
  "created_at": "2026-02-19T10:00:00Z",
  "message": "Chat session started. Send messages to test workflow."
}
```

**Save `session_id`** — you'll pass it with every message.

---

### Step 2 — Send a message (returns run_id immediately)

```
POST /workflows/chat/send
```

**Request body**

```json
{
  "session_id": "session_abc123...",
  "message": "Analyze this customer feedback: Great product, fast shipping!",
  "execute_workflow": true
}
```

| Field | Required | Notes |
|---|---|---|
| `session_id` | Yes | From Step 1 |
| `message` | Yes | User's text |
| `execute_workflow` | No | `true` by default. Set `false` to save message without running. |

**Response (immediate — do not wait for workflow to finish)**

```json
{
  "session_id": "session_abc123...",
  "run_id": "run_7a3f...",
  "status": "executing",
  "message": "Connect to WebSocket for real-time updates.",
  "ws_url": "/ws/execution/run_7a3f..."
}
```

> **As soon as you get `run_id`, open the WebSocket.** The workflow starts 500ms later.

---

### Step 3 — Connect WebSocket for real-time events

```
WebSocket: ws://<host>/ws/execution/{run_id}
```

Or with TLS: `wss://<host>/ws/execution/{run_id}`

**WebSocket events you'll receive (JSON objects):**

#### `run_started`
```json
{
  "event": "run_started",
  "run_id": "run_7a3f...",
  "workflow_id": "wf_550e...",
  "timestamp": "2026-02-19T10:00:00.500Z"
}
```
Show a loading indicator.

#### `step_started`
```json
{
  "event": "step_started",
  "run_id": "run_7a3f...",
  "step_id": "step_abc...",
  "step_name": "Sentiment Analyzer",
  "step_type": "agent",
  "timestamp": "2026-02-19T10:00:01Z"
}
```
Mark that agent as "running" in the UI.

#### `step_completed`
```json
{
  "event": "step_completed",
  "run_id": "run_7a3f...",
  "step_id": "step_abc...",
  "step_name": "Sentiment Analyzer",
  "output_summary": { "sentiment": "positive", "score": 0.95 },
  "timestamp": "2026-02-19T10:00:03Z"
}
```
Mark that agent as "done". Optionally show `output_summary`.

#### `step_failed`
```json
{
  "event": "step_failed",
  "run_id": "run_7a3f...",
  "step_id": "step_abc...",
  "step_name": "Sentiment Analyzer",
  "error": "LLM timeout after 30s",
  "timestamp": "2026-02-19T10:00:05Z"
}
```
Mark that agent as "failed". Show error.

#### `run_completed`
```json
{
  "event": "run_completed",
  "run_id": "run_7a3f...",
  "output": {
    "crew_result": "The customer feedback is overwhelmingly positive...",
    "sentiment": "positive"
  },
  "timestamp": "2026-02-19T10:00:10Z"
}
```
Extract the answer from `output.crew_result` (or `output.result` as fallback). Display in chat. Close WebSocket.

#### `run_failed`
```json
{
  "event": "run_failed",
  "run_id": "run_7a3f...",
  "error": "Workflow execution failed: ...",
  "timestamp": "2026-02-19T10:00:10Z"
}
```
Show an error message. Close WebSocket.

#### `hitl_interrupt` (Human-In-The-Loop)
```json
{
  "event": "run_completed",
  "run_id": "run_7a3f...",
  "output": {
    "status": "interrupted",
    "interrupt": {
      "agent_id": "agt_reviewer",
      "agent_name": "Content Reviewer",
      "message": "Please review this content before proceeding",
      "agent_output": { "draft": "..." },
      "allowed_actions": ["approve", "reject", "edit", "defer"]
    }
  }
}
```
When `output.status === "interrupted"`, show the HITL review panel (see HITL endpoints below).

---

### Step 4 (optional) — Get chat history

```
GET /workflows/chat/history/{session_id}
```

Returns all messages in the session.

---

### HITL endpoints (if the workflow has human approval nodes)

When you receive an `interrupted` status on the WebSocket, show the review UI and call:

```
POST /workflows/hitl/decide
```

**Request body**

```json
{
  "run_id": "run_7a3f...",
  "action": "approve",
  "actor": "user@company.com",
  "rationale": "Content looks good",
  "payload": {}
}
```

| `action` value | What it does |
|---|---|
| `approve` | Resume workflow as-is |
| `reject` | Stop the workflow |
| `edit` | Resume with modified input (`payload.changes` required) |
| `defer` | Pause for later (`payload.defer_until` ISO timestamp) |

After posting, reconnect to the WebSocket on the same `run_id` to see the resumed execution events.

---

## 5. A2UI — How to Render the Progress UI

### What is A2UI?

A2UI is a simple data format the backend uses to describe a progress step-list. Instead of the backend sending HTML, it sends data and the **frontend decides how to render it**.

Think of it like: the backend says *"here are 5 steps, step 2 is running"* and you render that however you want.

### Minimal rendering approach

You don't need to implement the full A2UI spec. Here's the simplest approach:

**Keep 3 reactive variables:**
```javascript
let steps = []        // array of step objects
let finalOutput = ""  // the final answer text
let surfaceVisible = false
```

**On each stream event:**
```javascript
function handleMessage(msg) {
  if (msg.type === "beginRendering") {
    surfaceVisible = true  // show the step list panel
  }

  if (msg.type === "dataModelUpdate") {
    if (msg.data.steps !== undefined) {
      steps = msg.data.steps  // replace entire array
    }
    if (msg.data.final_output !== undefined && msg.data.final_output !== "") {
      finalOutput = msg.data.final_output  // show the answer
    }
  }

  if (msg.type === "deleteSurface") {
    surfaceVisible = false  // hide the step list
    steps = []
  }
}
```

**Render the steps** (pseudocode / React-style):
```jsx
{surfaceVisible && (
  <div className="step-list">
    {steps.map(step => (
      <div key={step.id} className={`step step--${step.status}`}>
        <Icon name={step.icon} />
        <span className="step-label">{step.label}</span>
        {step.detail && <span className="step-detail">{step.detail}</span>}
        <StatusBadge status={step.status} />
      </div>
    ))}
  </div>
)}

{finalOutput && (
  <div className="chat-message assistant">
    {finalOutput}
  </div>
)}
```

### Step object shape (for reference)

```typescript
interface Step {
  id: string;       // e.g. "guardrails", "enhancer", "agent_MyAgent"
  icon: string;     // Material Icons name — e.g. "shield", "auto_fix_high"
  label: string;    // e.g. "Guardrails", "Prompt Enhancement"
  detail: string;   // extra context, may be ""
  status: "pending" | "running" | "completed" | "failed" | "interrupted" | "skipped";
}
```

### Icon library

Add Material Icons to your HTML `<head>`:
```html
<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
```

Use: `<span class="material-icons">{step.icon}</span>`

---

## 6. Error Handling Reference

### App Manager SSE errors

| When | What to do |
|---|---|
| `400` before stream opens | Show "This application is not available yet" |
| `401` before stream opens | Redirect to login |
| Stream closes with no `final_output` | Show "Something went wrong, please try again" |
| `deleteSurface` arrives early | Treat as an error, show retry button |
| Network drops mid-stream | Catch `ReadableStream` close event, show retry |

### Workflow WebSocket errors

| When | What to do |
|---|---|
| WebSocket closes before `run_completed` | Show "Connection lost — check execution history" |
| `run_failed` event | Show error message from `event.error` field |
| `step_failed` event | Mark that step red, but wait for `run_completed` before deciding overall status |
| Session not found (404 on `/chat/send`) | Clear local session, call `/chat/start` again |

### General rule

Always show the user a human-friendly message. Log the technical error to console for debugging.

---

## 7. Copy-Paste Code Snippets

### App Manager — fetch + ReadableStream SSE client

```javascript
async function sendAppMessage(appId, message, sessionId, authToken, onEvent, onDone) {
  const controller = new AbortController();

  const response = await fetch(`/api/applications/${appId}/chat/stream`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${authToken}`,
    },
    body: JSON.stringify({
      message,
      session_id: sessionId || undefined,
    }),
    signal: controller.signal,
  });

  if (!response.ok) {
    throw new Error(`HTTP ${response.status}: ${await response.text()}`);
  }

  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  let buffer = '';

  try {
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;

      buffer += decoder.decode(value, { stream: true });

      // Split on SSE event boundaries
      const lines = buffer.split('\n');
      buffer = lines.pop(); // Keep incomplete last line in buffer

      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const jsonStr = line.slice(6).trim();
          if (!jsonStr) continue;
          try {
            const msg = JSON.parse(jsonStr);
            onEvent(msg); // Call your event handler
          } catch (e) {
            console.warn('Failed to parse A2UI event:', jsonStr);
          }
        }
      }
    }
  } finally {
    reader.releaseLock();
    onDone();
  }

  return controller; // Caller can call controller.abort() to cancel
}


// ---- Usage ----

let steps = [];
let finalOutput = '';
let surfaceVisible = false;

await sendAppMessage(
  'app-uuid-here',
  'What are the open tickets?',
  'session-uuid-here',
  'bearer-token-here',
  (msg) => {
    if (msg.type === 'beginRendering') {
      surfaceVisible = true;
    }
    if (msg.type === 'dataModelUpdate') {
      if (msg.data.steps !== undefined)      steps = msg.data.steps;
      if (msg.data.final_output)             finalOutput = msg.data.final_output;
    }
    if (msg.type === 'deleteSurface') {
      surfaceVisible = false;
      steps = [];
    }
    // Re-render your UI here
  },
  () => {
    console.log('Stream complete');
  }
);
```

---

### Workflow — start session + send + WebSocket

```javascript
// Step 1: Start session (once)
async function startWorkflowSession(workflowId, authToken) {
  const res = await fetch('/workflows/chat/start', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${authToken}`,
    },
    body: JSON.stringify({
      workflow_id: workflowId,
      mode: 'test',
    }),
  });
  const data = await res.json();
  return data.session_id; // Save this
}

// Step 2: Send message, get run_id
async function sendWorkflowMessage(sessionId, message, authToken) {
  const res = await fetch('/workflows/chat/send', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${authToken}`,
    },
    body: JSON.stringify({
      session_id: sessionId,
      message,
      execute_workflow: true,
    }),
  });
  const data = await res.json();
  return data.run_id; // Use this for WebSocket
}

// Step 3: Open WebSocket
function watchExecution(runId, onEvent) {
  const ws = new WebSocket(`ws://${location.host}/ws/execution/${runId}`);

  ws.onmessage = (e) => {
    const event = JSON.parse(e.data);
    onEvent(event);

    // Close when done
    if (event.event === 'run_completed' || event.event === 'run_failed') {
      ws.close();
    }
  };

  ws.onerror = () => onEvent({ event: 'run_failed', error: 'WebSocket error' });
  ws.onclose = () => onEvent({ event: 'ws_closed' });

  return ws;
}

// ---- Usage ----

const sessionId = await startWorkflowSession('wf_abc123...', token);

// On each user message:
const runId = await sendWorkflowMessage(sessionId, userMessage, token);

// Open WebSocket immediately (before the 500ms delay fires):
watchExecution(runId, (event) => {
  switch (event.event) {
    case 'run_started':
      showLoading();
      break;
    case 'step_started':
      markStepRunning(event.step_name);
      break;
    case 'step_completed':
      markStepDone(event.step_name, event.output_summary);
      break;
    case 'step_failed':
      markStepFailed(event.step_name, event.error);
      break;
    case 'run_completed':
      if (event.output?.status === 'interrupted') {
        showHITLReviewPanel(event.output.interrupt);
      } else {
        const answer = event.output?.crew_result
                    || event.output?.result
                    || JSON.stringify(event.output);
        showAnswer(answer);
      }
      break;
    case 'run_failed':
      showError(event.error);
      break;
  }
});
```

---

### HITL decision

```javascript
async function submitHITLDecision(runId, action, actor, rationale, payload, authToken) {
  const res = await fetch('/workflows/hitl/decide', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${authToken}`,
    },
    body: JSON.stringify({
      run_id: runId,
      action,     // "approve" | "reject" | "edit" | "defer"
      actor,      // user's email or name
      rationale,  // optional comment
      payload,    // {} for approve/reject, { changes: {...} } for edit, { defer_until: "ISO" } for defer
    }),
  });
  return res.json();
}
```

---

## Summary Cheat Sheet

| Task | Method | URL |
|---|---|---|
| Chat with published app (streaming) | `POST` | `/api/applications/{id}/chat/stream` |
| Start workflow test session | `POST` | `/workflows/chat/start` |
| Send workflow message (get run_id) | `POST` | `/workflows/chat/send` |
| Watch workflow execution live | WebSocket | `ws://host/ws/execution/{run_id}` |
| Get workflow step snapshot | `GET` | `/workflows/execution/{run_id}/steps` |
| Get chat history (workflow) | `GET` | `/workflows/chat/history/{session_id}` |
| Submit HITL decision | `POST` | `/workflows/hitl/decide` |
| Get HITL review context | `GET` | `/workflows/hitl/context/{run_id}` |
| List pending HITL reviews | `GET` | `/workflows/hitl/pending` |



===================================================================================

## For YASH Reference: 

The real situation with React + A2UI

  The official A2UI React renderer is marked "Coming Q1 2026" — it's either just landing or still in progress. There is no 
  stable, battle-tested official React package yet.

  What does exist on npm (@a2ui-sdk/react, @zhama/a2ui) are community/unofficial implementations — not Google-maintained.  

  ---
  What to tell your React developer

  The good news first

  Our backend is 100% A2UI v0.8 spec-compliant. Whatever React package becomes stable — official or community — it will    
  work with our SSE stream without any backend changes. The JSONL we emit is exactly what the spec defines.

  For right now — two options

  ---
  Option 1: Try @a2ui-sdk/react (community SDK)

  npm install @a2ui-sdk/react

  Based on search results, the API looks like this:

  import { A2UIProvider, A2UIRenderer, useA2UIMessageHandler } from '@a2ui-sdk/react';

  function AppChat({ appId, token }) {
    return (
      <A2UIProvider>
        <ChatWithStream appId={appId} token={token} />
      </A2UIProvider>
    );
  }

  function ChatWithStream({ appId, token }) {
    const { processMessage } = useA2UIMessageHandler();

    const sendMessage = async (userMessage, sessionId) => {
      const response = await fetch(`/api/applications/${appId}/chat/stream`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${token}`,
        },
        body: JSON.stringify({ message: userMessage, session_id: sessionId }),
      });

      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let buffer = '';

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split('\n');
        buffer = lines.pop();

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const msg = JSON.parse(line.slice(6));
            processMessage(msg); // <-- feeds each A2UI event into the renderer
          }
        }
      }
    };

    return <A2UIRenderer />;  // renders whatever the stream describes
  }

  Caveat: This SDK is community-maintained. Tell your dev to check the package README on npm for the exact hook names      
  before using — the names above are from search snippets and could differ slightly.

  ---
  Option 2: Manual rendering (most reliable right now)

  Since the official React support isn't out yet, your developer writes a small hook and component using the guide I       
  already produced. This is what Google's own quickstart recommends for frameworks without a stable renderer — parse the   
  messages yourself and render with your existing component library (MUI, shadcn, Tailwind, etc.).

  // useA2UIStream.js — ~40 lines, your own hook
  function useA2UIStream() {
    const [steps, setSteps] = useState([]);
    const [finalOutput, setFinalOutput] = useState('');
    const [visible, setVisible] = useState(false);

    const connect = async (appId, message, sessionId, token) => {
      const res = await fetch(`/api/applications/${appId}/chat/stream`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${token}` },
        body: JSON.stringify({ message, session_id: sessionId }),
      });
      const reader = res.body.getReader();
      const decoder = new TextDecoder();
      let buf = '';
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        buf += decoder.decode(value, { stream: true });
        const lines = buf.split('\n'); buf = lines.pop();
        for (const line of lines) {
          if (!line.startsWith('data: ')) continue;
          const msg = JSON.parse(line.slice(6));
          if (msg.type === 'beginRendering')                  setVisible(true);
          if (msg.type === 'dataModelUpdate' && msg.data.steps)        setSteps(msg.data.steps);
          if (msg.type === 'dataModelUpdate' && msg.data.final_output) setFinalOutput(msg.data.final_output);
          if (msg.type === 'deleteSurface')  { setVisible(false); setSteps([]); }
        }
      }
    };

    return { steps, finalOutput, visible, connect };
  }

  ---
  Summary — what to hand the React dev

  Item: Official A2UI React package
  Answer: Not stable yet — Q1 2026
  ────────────────────────────────────────
  Item: Community option
  Answer: npm install @a2ui-sdk/react — check the README
  ────────────────────────────────────────
  Item: Our backend changes needed?
  Answer: None — stream is already A2UI v0.8 compliant
  ────────────────────────────────────────
  Item: Safest path right now
  Answer: Write the 40-line custom hook above
  ────────────────────────────────────────
  Item: When official React renderer releases
  Answer: Drop in A2UIProvider + A2UIRenderer, point it at the same SSE endpoint — done

  The backend is ready. The frontend is the only moving piece, and it's a 40-line hook either way.

  Sources:
  - https://a2ui.org/roadmap/
  - https://github.com/google/A2UI
  - https://www.npmjs.com/package/@a2ui-sdk/react
  - https://blog.logrocket.com/a2ui-better-way-ship-agents/